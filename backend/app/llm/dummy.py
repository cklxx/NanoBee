from __future__ import annotations

import json
from typing import Any, Dict, List

from .base import LLMClient, LLMMessage


class DummyLLM(LLMClient):
    """A lightweight stand-in model used for local demos.

    The initializer returns a predictable scaffold. Coding sessions echo back
    a short note to simulate a plan. The harness provides the real behavior.
    """

    async def chat(self, messages: List[LLMMessage], tools: list | None = None) -> Dict[str, Any]:
        content = messages[-1]["content"] if messages else ""
        if "init" in content.lower():
            files: Dict[str, str] = {
                "README.md": "# Demo Project\n\nGenerated by DummyLLM initializer.\n",
                "src/app.py": "def main():\n    return 'hello from demo'\n\nif __name__ == '__main__':\n    print(main())\n",
                "tests/__init__.py": "",
                "tests/test_smoke.py": "def test_placeholder():\n    assert True\n",
            }
            return {"files": files, "notes": "initializer stub"}
        return {"message": "dummy-response", "echo": content}
